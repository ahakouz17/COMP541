{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for p in (\"Knet\", \"Plots\", \"NBInclude\")\n",
    "    Pkg.installed(p) == nothing && Pkg.add(p);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Knet, Plots, NBInclude;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function constructFeatDict()\n",
    "    # read features for all proteins\n",
    "    f = open(\"yeast_feature_all.csv\");\n",
    "    lines = readlines(f);\n",
    "    close(f);\n",
    "    numberOfProteins = length(lines) \n",
    "    featureNames = String.(split(lines[1],\",\")); \n",
    "    d = length(featureNames) - 1 # number of features per protein\n",
    "    proteins = lines[2:numberOfProteins];\n",
    "    featuresDict = Dict{String,Any}()\n",
    "    for p in proteins\n",
    "        featureVect = String.(split(p, \",\"));\n",
    "        featuresDict[featureVect[1]] = parse.(Float32, featureVect[2:d+1]) # featureVect[1] is the protein UniProt ID \n",
    "    end\n",
    "    f = open(\"test_datasets/Negatome_features.csv\");\n",
    "    lines = readlines(f);\n",
    "    close(f);\n",
    "    numberOfProteins = length(lines) \n",
    "    featureNames = String.(split(lines[1],\",\")); \n",
    "    d = length(featureNames) - 1 # number of features per protein\n",
    "    proteins = lines[2:numberOfProteins];\n",
    "    for p in proteins\n",
    "        featureVect = String.(split(p, \",\"));\n",
    "        if(\"\" in featureVect[2:d+1])\n",
    "            continue\n",
    "        end\n",
    "        featuresDict[featureVect[1]] = parse.(Float32, featureVect[2:d+1]) # featureVect[1] is the protein UniProt ID \n",
    "    end\n",
    "    return featuresDict;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function loaddata(featuresDict)\n",
    "    f = open(\"yeast_protein_pair.csv\")\n",
    "    lines = readlines(f);\n",
    "    close(f)\n",
    "    f = open(\"test_datasets/Negatome_pairs.csv\")\n",
    "    negsamples = readlines(f);\n",
    "    close(f)\n",
    "    n = length(lines); # number of samples/ protein pairs\n",
    "    samples = lines[2:end - 1];\n",
    "    possamples = samples[1:17257]\n",
    "    concatAB1 = []\n",
    "    ygold = Array{UInt8,1}(length(possamples) + length(negsamples));\n",
    "    i = 1;\n",
    "    for s in possamples\n",
    "        s = String.(split(s, \",\"));\n",
    "        push!(concatAB1, hcat(reshape(mat(featuresDict[s[1]]), 1, 1164), reshape(mat(featuresDict[s[2]]), 1, 1164)))\n",
    "        ygold[i] = 0x02;\n",
    "        i += 1;\n",
    "    end\n",
    "    \n",
    "    \n",
    "    n = length(negsamples); # number of samples/ protein pairs\n",
    "    for s in negsamples\n",
    "        s = String.(split(s, \"\\t\"));\n",
    "        if s[1] in keys(featuresDict) && s[2] in keys(featuresDict) \n",
    "            push!(concatAB1, hcat(reshape(mat(featuresDict[s[1]]), 1, 1164), reshape(mat(featuresDict[s[2]]), 1, 1164)))\n",
    "            ygold[i] = 0x01;\n",
    "            i += 1;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    concatAB = vcat(map(Atype, concatAB1)...)\n",
    "    return concatAB, ygold\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function winit(h...)\n",
    "    w = Any[]\n",
    "    for i=2:length(h)\n",
    "        push!(w, 0.01*randn(h[i],h[i-1]))\n",
    "        push!(w, zeros(h[i],1))\n",
    "    end\n",
    "    map(Atype, w)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function dividedataset(data, ygold, trnper, devper, tstper; batchsize=64, dev=true) # 0.58, 0.17, 0.25\n",
    "    nopos = 17257 # number of total positive samples\n",
    "    noneg = 6222\n",
    "    # construct a 1:1 ratio of positive and negative samples as the data set\n",
    "    posdata = data[1 : nopos, :];\n",
    "    posygold = ygold[1 : nopos];\n",
    "    negdata = data[nopos + 1 : end, :];\n",
    "    negygold = ygold[nopos + 1 : end];\n",
    "    \n",
    "    # pick noneg positive samples randomly\n",
    "    indneg = randperm(noneg)\n",
    "    data = vcat(posdata[indneg[1:end],:], negdata)\n",
    "    ygold = vcat(posygold[indneg[1:end]], negygold)\n",
    "    println(summary(data))\n",
    "    nosamples = size(data,1)\n",
    "    notst = Int(floor(tstper * nosamples))\n",
    "    notrn = Int(floor(trnper * nosamples))\n",
    "    nodev = nosamples - notrn - notst\n",
    "    ind = randperm(nosamples)\n",
    "    \n",
    "    xtrn = data[ind[1:notrn],:];\n",
    "    ytrn = ygold[ind[1:notrn]];\n",
    "    \n",
    "    xtst = data[ind[notrn+1:notrn+notst], :];\n",
    "    ytst = ygold[ind[notrn+1:notrn+notst]];\n",
    "    \n",
    "    dtrn = minibatchi(xtrn',ytrn,batchsize);\n",
    "    dtst = minibatchi(xtst',ytst,batchsize);\n",
    "    \n",
    "    if (dev)\n",
    "        xdev = data[ind[notrn+1:notrn+nodev], :];\n",
    "        ydev = ygold[ind[notrn+1:notrn+nodev]];\n",
    "        ddev = minibatchi(xdev',ydev,batchsize);\n",
    "        return dtrn, ddev, dtst\n",
    "    else\n",
    "        return dtrn, dtst\n",
    "    end\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function predictSep(w, x; pdrop=(0,0))\n",
    "    wa = w[1:6]\n",
    "    wb = w[7:12]\n",
    "    wm = w[13:end]\n",
    "    xa = x[1:1164,:]\n",
    "    xb = x[1165:end,:]\n",
    "    \n",
    "    for i=1:2:length(wa)\n",
    "        xa = dropout(xa, pdrop[i==1?1:2])\n",
    "        xa = wa[i]*xa .+ wa[i+1]\n",
    "        xa = relu.(xa)                      \n",
    "    end\n",
    "    \n",
    "    for i=1:2:length(wb)\n",
    "        xb = dropout(xb, pdrop[i==1?1:2])\n",
    "        xb = wb[i]*xb .+ wb[i+1]\n",
    "        xb = relu.(xb)                         \n",
    "    end\n",
    "    \n",
    "    xm = vcat(xa, xb)\n",
    "    \n",
    "    for i=1:2:length(wm)\n",
    "        xm = dropout(xm, pdrop[i==1?2:1])\n",
    "        xm = wm[i]*xm .+ wm[i+1]\n",
    "        if i<length(wm)-1\n",
    "            xm = relu.(xm)   ## apply RELU to all but the final layer's output                        \n",
    "        end\n",
    "    end\n",
    "    return xm\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train model(w) with SGD and return a list containing w for every epoch\n",
    "function trainSep!(w, optims,data,predict, ddev; epochs=100,lr=.01,o...) #, decay=1.0\n",
    "    #trnloss = Any[loss(w,data,predict)]\n",
    "    #trnerr = Any[zeroone(w,data,predict)]\n",
    "    #devloss = Any[loss(w,ddev,predict)]\n",
    "    #deverr = Any[zeroone(w,ddev,predict)]\n",
    "    for epoch in 1:epochs\n",
    "        for (x,y) in data\n",
    "            dw = lossgradient(w,x,y, predict; o...)\n",
    "            #@show (map(vecnorm, dw))\n",
    "            update!(w, dw, optims)\n",
    "        end\n",
    "        #push!(trnloss, loss(w,data,predict))\n",
    "        #push!(trnerr, zeroone(w,data,predict))\n",
    "        #push!(devloss, loss(w,ddev,predict))\n",
    "        #push!(deverr, zeroone(w,ddev,predict))\n",
    "        if(epoch % 10 == 0)\n",
    "            println((:epoch,epoch,:trn,accuracyi(w,data,predict),:tst,accuracyi(w,ddev,predict)));\n",
    "        end\n",
    "\n",
    "    end\n",
    "    #return trnloss, trnerr, devloss, deverr\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss(w,x,ygold, predict; o...) = nll(predict(w,x; o...),ygold);\n",
    "loss(w, data, predict; o...) = mean(loss(w,x,y,predict; o...) for (x,y) in data);\n",
    "zeroone(w,data,predict; o...) = 1 - accuracyi(w,data,predict);\n",
    "lossgradient = grad(loss);\n",
    "report(epoch)=println((:epoch,epoch,:trn,accuracyi(w,dtrn,predict),:dev,accuracyi(w,ddev,predict)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function params(ws; optim=\"Sgd\", lr=0.01, gamma=0.95, eps=1e-6, rho=0.9, beta1=0.9, beta2=0.95)\n",
    "    prms = Any[]\n",
    "\n",
    "    for i=1:length(ws)\n",
    "        w = ws[i]\n",
    "        if optim == \"Sgd\"\n",
    "            prm = Sgd(;lr=lr)\n",
    "        elseif optim == \"Momentum\"\n",
    "            prm = Momentum(lr=lr, gamma=gamma)\n",
    "        elseif optim == \"Nesterov\"\n",
    "            prm = Nesterov(lr=lr, gamma=gamma)\n",
    "        elseif optim == \"Adagrad\"\n",
    "            prm = Adagrad(lr=lr, eps=eps)\n",
    "        elseif optim == \"Adadelta\"\n",
    "            prm = Adadelta(lr=lr, rho=rho, eps=eps)\n",
    "        elseif optim == \"Rmsprop\"\n",
    "            prm = Rmsprop(lr=lr, rho=rho, eps=eps)\n",
    "        elseif optim == \"Adam\"\n",
    "            prm = Adam(lr=lr, beta1=beta1, beta2=beta2, eps=eps)\n",
    "        else\n",
    "            error(\"Unknown optimization method!\")\n",
    "        end\n",
    "        push!(prms, prm)\n",
    "    end\n",
    "\n",
    "    return prms\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function accuracyi(ypred, ygold)\n",
    "    count = 0\n",
    "    for i in 1:size(ypred, 2)\n",
    "        if((ypred[1,i] >= ypred[2,i] && ygold[i]==1) || (ypred[1,i] <= ypred[2,i] && ygold[i]==2))\n",
    "            count +=1\n",
    "        end\n",
    "    end\n",
    "    return count/size(ypred, 2);\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function accuracyi(w, data, predict)\n",
    "    acc = 0;\n",
    "    for (x, y) in data\n",
    "        ypred = predict(w,x)\n",
    "        acc += accuracyi(ypred, y) \n",
    "    end\n",
    "    return acc/length(data)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function modelevaluation(w, data, pred; p=false)\n",
    "    tp=tn=fp=fn= 0    \n",
    "\n",
    "    for (x,y) in data\n",
    "        ypred = pred(w, x)\n",
    "        for i in 1:size(ypred, 2)\n",
    "            if(ypred[1,i] >= ypred[2,i] && y[i]==1)\n",
    "                tn += 1;\n",
    "            elseif(ypred[1,i] <= ypred[2,i] && y[i]==2)\n",
    "                tp += 1\n",
    "            elseif(ypred[1,i] >= ypred[2,i] && y[i]==2)\n",
    "                fp += 1\n",
    "            else\n",
    "                fn += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    accuracy = (tp + tn) / (tp + tn + fn + fp+1e-06)\n",
    "    recall = tp / (tp + fn +1e-06)\n",
    "    specifity = tn / (tn + fp+1e-06)\n",
    "    precision = tp / (tp + fp +1e-06)\n",
    "    mcc = (tp*tn-fp*fn)/(sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))+1e-06)\n",
    "    f1 = (tp*2)/(tp*2+fp+fn+1e-06)\n",
    "    npv = (tn)/(tn + fn + 1e-06)\n",
    "    if (p)\n",
    "        println(\"TP: \", tp, \" , TN: \", tn, \" , FP: \", fp, \" , FN: \", fn);\n",
    "        println(\"Model evaluation:\");\n",
    "        println(\"Accuracy : \", accuracy);\n",
    "        println(\"Precision : \", precision);\n",
    "        println(\"NPV : \", npv);\n",
    "        println(\"Sensitivity / Recall : \", recall);\n",
    "        println(\"Specifity : \", specifity);\n",
    "        println(\"MCC : \", mcc);\n",
    "        println(\"F1 : \", f1);\n",
    "    end\n",
    "    \n",
    "    return accuracy,recall,specifity,precision,mcc,f1,npv;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input X matrix and gold labels Y\n",
    "# Output list of minibatches (x, y)\n",
    "function minibatchi(X, Y, batchsize)\n",
    "    data = Any[] \n",
    "    meanx = mean(X,2);\n",
    "    if(gpu() < 0)\n",
    "        # CPU\n",
    "        stdx=std(X,2);\n",
    "    else\n",
    "        # for GPU, manually calculate std for Knet arrays\n",
    "        stdx= sqrt.(sum(abs2.(X.-meanx), 2)/(size(X,2) - 1));\n",
    "    end\n",
    "    X = (X.-meanx) ./ stdx;\n",
    "\n",
    "    for i = 1:batchsize:size(X, 2)\n",
    "        bl = min(i + batchsize - 1, size(X, 2))\n",
    "        push!(data, (X[:, i:bl], Y[i:bl]))\n",
    "    end\n",
    "    return data\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train!(w, optims,data,predict, ddev; epochs=100,lr=.5,o...)\n",
    "    #trnloss = Any[loss(w,data,predict)]\n",
    "    #trnerr = Any[zeroone(w,data,predict)]\n",
    "    #devloss = Any[loss(w,ddev,predict)]\n",
    "    #deverr = Any[zeroone(w,ddev,predict)]\n",
    "    for epoch in 1:epochs\n",
    "        if(epoch % 10 == 0)\n",
    "            println((:epoch,epoch,:trn,accuracyi(w,data,predict),:tst,accuracyi(w,ddev,predict)));\n",
    "        end\n",
    "        for (x,y) in data\n",
    "            dw = lossgradient(w,x,y, predict; o...)\n",
    "            #@show (map(vecnorm, dw))\n",
    "            update!(w, dw, optims)\n",
    "#             for i in 1:length(w)\n",
    "#                w[i] -= lr * dw[i]\n",
    "#             end\n",
    "        end\n",
    "        #push!(trnloss, loss(w,data,predict))\n",
    "        #push!(trnerr, zeroone(w,data,predict))\n",
    "        #push!(devloss, loss(w,ddev,predict))\n",
    "        #push!(deverr, zeroone(w,ddev,predict))\n",
    "    end\n",
    "    #return trnloss, trnerr , devloss, deverr\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function predict(w,x; pdrop=(0,0))\n",
    "    for i=1:2:length(w)\n",
    "        x = dropout(x, pdrop[i==1 || i == length(w)-1?1:2])\n",
    "        x = w[i]*x .+ w[i+1]\n",
    "        if i < length(w)-1\n",
    "            x = relu.(x)   ## apply RELU to all but the final layer's output                        \n",
    "        end\n",
    "    end\n",
    "    return x\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Atype = gpu() >= 0 ? KnetArray{Float32} : Array{Float32};\n",
    "setseed(1);\n",
    "\n",
    "# number of input features per protein\n",
    "NOINPUTS = 1164;\n",
    "# number of input features for the protein pair\n",
    "NOCONCAT = NOINPUTS * 2;\n",
    "# output is a one-hot-vector 10 -> not interacting, 01 -> intracting\n",
    "NOOUTPUTS = 2;\n",
    "\n",
    "# the percentages used for evaluationg models in the paper\n",
    "trnper = 0.75;\n",
    "tstper = 0.25;\n",
    "devper = 1 - trnper - tstper;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[7.5 1.90476 … 0.002937 0.001369; 4.14971 1.4646 … 0.000999 -0.001443; … ; 5.74713 0.574713 … 0.006669 0.00223; 9.77444 3.00752 … 0.006374 0.00367], UInt8[0x02, 0x02, 0x02, 0x02, 0x02, 0x02, 0x02, 0x02, 0x02, 0x02  …  0x38, 0x2c, 0x30, 0x2e, 0x30, 0x30, 0x30, 0x32, 0x30, 0x33])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresDict = constructFeatDict();\n",
    "concatAB, ygold = loaddata(featuresDict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12444×2328 Array{Float32,2}\n"
     ]
    }
   ],
   "source": [
    "BATCHSIZE = 64;\n",
    "dtrn, ddev, dtst = dividedataset(concatAB, ygold, trnper, devper, tstper; batchsize= BATCHSIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the number of hidden units in the hidden layers of the DeepPPI-CON model\n",
    "HIDDENSSEP = Any[NOINPUTS, 512, 256, 128]; \n",
    "HIDDENSMER = Any[256, 128, NOOUTPUTS]\n",
    "NOEPOCH = 30;\n",
    "BATCHSIZE = 64;\n",
    "PDROP = (0, 0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12444×2328 Array{Float32,2}\n",
      "(:epoch, 10, :trn, 0.9476407017317136, :tst, 0.9344256933542647)\n",
      "(:epoch, 20, :trn, 0.995291095890411, :tst, 0.962805795395081)\n",
      "(:epoch, 30, :trn, 0.9972174657534246, :tst, 0.9633290816326531)\n",
      " 99.946530 seconds (10.43 M allocations: 43.746 GiB, 5.29% gc time)\n",
      "Dataset1\n",
      "Training: min. loss =0.008437758, min. error =0.0027825342465753744\n",
      "Test: min. loss =0.17190474, min. error =0.03667091836734693\n",
      "TP: 1471 , TN: 1525 , FP: 67 , FN: 48\n",
      "Model evaluation:\n",
      "Accuracy : 0.9630343937759452\n",
      "Precision : 0.9564369304574531\n",
      "NPV : 0.9694850597778225\n",
      "Sensitivity / Recall : 0.968400262693614\n",
      "Specifity : 0.9579145722626164\n",
      "MCC : 0.9261183930042733\n",
      "F1 : 0.9623814193776966\n",
      "12444×2328 Array{Float32,2}\n",
      "(:epoch, 10, :trn, 0.9167965721116569, :tst, 0.9038625065410779)\n",
      "(:epoch, 20, :trn, 0.9955899457224089, :tst, 0.9665423861852432)\n",
      "(:epoch, 30, :trn, 0.9973022744895321, :tst, 0.9641957744636316)\n",
      "112.256977 seconds (8.35 M allocations: 43.642 GiB, 4.85% gc time)\n",
      "Dataset2\n",
      "Training: min. loss =0.006433078, min. error =0.0026977255104678743\n",
      "Test: min. loss =0.15815867, min. error =0.03580422553636842\n",
      "TP: 1517 , TN: 1483 , FP: 46 , FN: 65\n",
      "Model evaluation:\n",
      "Accuracy : 0.9643201539812536\n",
      "Precision : 0.9705694171653426\n",
      "NPV : 0.9580103352984428\n",
      "Sensitivity / Recall : 0.9589127680411423\n",
      "Specifity : 0.9699149764748757\n",
      "MCC : 0.9287037414520041\n",
      "F1 : 0.9647058820461984\n",
      "12444×2328 Array{Float32,2}\n",
      "(:epoch, 10, :trn, 0.9661996801499095, :tst, 0.9481374280481423)\n",
      "(:epoch, 20, :trn, 0.9962542808219178, :tst, 0.9706632653061225)\n",
      "(:epoch, 30, :trn, 0.9971104452054794, :tst, 0.9738520408163265)\n",
      "103.551771 seconds (8.35 M allocations: 43.642 GiB, 5.27% gc time)\n",
      "Dataset3\n",
      "Training: min. loss =0.0070900223, min. error =0.002889554794520577\n",
      "Test: min. loss =0.11271677, min. error =0.02614795918367352\n",
      "TP: 1505 , TN: 1524 , FP: 40 , FN: 42\n",
      "Model evaluation:\n",
      "Accuracy : 0.9736419154697391\n",
      "Precision : 0.9741100317319675\n",
      "NPV : 0.9731800760069093\n",
      "Sensitivity / Recall : 0.9728506781041688\n",
      "Specifity : 0.9744245518066339\n",
      "MCC : 0.9472826700471557\n",
      "F1 : 0.9734799479387193\n",
      "12444×2328 Array{Float32,2}\n",
      "(:epoch, 10, :trn, 0.9510875710777978, :tst, 0.9360200811093667)\n",
      "(:epoch, 20, :trn, 0.9971104452054794, :tst, 0.9697066326530612)\n",
      "(:epoch, 30, :trn, 0.9986087328767124, :tst, 0.967155612244898)\n",
      " 99.635059 seconds (8.35 M allocations: 43.642 GiB, 5.33% gc time)\n",
      "Dataset4\n",
      "Training: min. loss =0.0037179184, min. error =0.0013912671232876317\n",
      "Test: min. loss =0.16473103, min. error =0.03284438775510201\n",
      "TP: 1489 , TN: 1519 , FP: 63 , FN: 40\n",
      "Model evaluation:\n",
      "Accuracy : 0.9668916743918703\n",
      "Precision : 0.9594072158766705\n",
      "NPV : 0.9743425266360856\n",
      "Sensitivity / Recall : 0.9738391098928455\n",
      "Specifity : 0.9601769905435037\n",
      "MCC : 0.933882913221492\n",
      "F1 : 0.9665692953695004\n",
      "12444×2328 Array{Float32,2}\n",
      "(:epoch, 10, :trn, 0.9786584873352286, :tst, 0.9523973050758765)\n",
      "(:epoch, 20, :trn, 0.9960402397260274, :tst, 0.9641957744636316)\n",
      "(:epoch, 30, :trn, 0.9976455479452054, :tst, 0.9627158555729983)\n",
      "103.417366 seconds (8.35 M allocations: 43.642 GiB, 5.21% gc time)\n",
      "Dataset5\n",
      "Training: min. loss =0.0068566725, min. error =0.0023544520547945647\n",
      "Test: min. loss =0.16683316, min. error =0.037284144427001675\n",
      "TP: 1524 , TN: 1472 , FP: 83 , FN: 32\n",
      "Model evaluation:\n",
      "Accuracy : 0.9630343937759452\n",
      "Precision : 0.9483509639400429\n",
      "NPV : 0.9787234036045721\n",
      "Sensitivity / Recall : 0.9794344466713145\n",
      "Specifity : 0.9466237936034573\n",
      "MCC : 0.9265661658557122\n",
      "F1 : 0.9636421116144034\n"
     ]
    }
   ],
   "source": [
    "accuracy =[]\n",
    "recall=[]\n",
    "specifity=[]\n",
    "precision= []\n",
    "mcc=[]\n",
    "f1=[]\n",
    "npv=[]\n",
    "accuracyt= recalli=specifityi=precisioni=mcci = 0.0\n",
    "for i in 1:5\n",
    "    #setseed(i);\n",
    "    wa = winit(HIDDENSSEP...);\n",
    "    wb = winit(HIDDENSSEP...);\n",
    "    wMerged = winit(HIDDENSMER...);\n",
    "    w = vcat(wa, wb, wMerged);\n",
    "    \n",
    "    #dtrn, ddev, dtst = dividedataset(concatAB, ygold, trnper, devper, tstper; batchsize= BATCHSIZE);\n",
    "    dtrn, dtst = dividedataset(concatAB, ygold, trnper, devper, tstper; batchsize= BATCHSIZE, dev=false);\n",
    "    \n",
    "    optims = params(w; optim=\"Momentum\", lr=0.01, gamma=0.9);\n",
    "    #@time trnloss, trnerr, tstloss, tsterr=trainSep!(w, optims, dtrn, predictSep, ddev; pdrop=PDROP, epochs=NOEPOCH) \n",
    "    @time trainSep!(w, optims, dtrn, predictSep, dtst; pdrop=PDROP, epochs=NOEPOCH) \n",
    "    \n",
    "    println(\"Dataset\", i)\n",
    "    println(\"Training: min. loss =\",loss(w,dtrn,predictSep),\", min. error =\",zeroone(w,dtrn,predictSep))  \n",
    "    println(\"Test: min. loss =\",loss(w,dtst,predictSep),\", min. error =\",zeroone(w,dtst,predictSep))  \n",
    "    \n",
    "    accuracyt,recalli,specifityi,precisioni,mcci,f1i,npvi = modelevaluation(w, dtst, predictSep; p=true);\n",
    "    push!(accuracy, accuracyt)\n",
    "    push!(recall, recalli)\n",
    "    push!(specifity, specifityi)\n",
    "    push!(precision, precisioni)\n",
    "    push!(mcc, mcci)\n",
    "    push!(f1, f1i)\n",
    "    push!(npv, npvi)\n",
    "    \n",
    "    writedlm(\"DeepPPI_SepModel\"*string(i)*\".csv\", map(Array, w))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#summary(accuracy)\n",
    "open(\"DeepPPI-Sep_Scores_wNegatome.txt\", \"w\") do f\n",
    "    write(f, \"Dataset \\tAccuracy\\t\\t\\tPrecision\\t\\t\\tnpv      \\t\\t\\tRecall   \\t\\t\\tSpecifity\\t\\t\\tMCC\\n\")\n",
    "    write(f, \"__________________________________________________________________________________________________________________________________\\n\")\n",
    "    for i in 1:5\n",
    "        write(f, \"dataset\"*string(i)*\"\\t\"*string(accuracy[i]) *\"\\t\"* string(precision[i]) *\"\\t\"* string(npv[i]) *\"\\t\"* string(recall[i]) *\"\\t\"*  string(specifity[i]) *\"\\t\"*  string(mcc[i]) *\"\\n\")\n",
    "    end\n",
    "    write(f, \"__________________________________________________________________________________________________________________________________\\n\")\n",
    "    write(f, \"Average\"*\"\\t\\t\"*string(mean(accuracy)) *\"\\t\"* string(mean(precision))  *\"\\t\"* string(mean(npv)) *\"\\t\"* string(mean(recall)) *\"\\t\"*  string(mean(specifity)) *\"\\t\"*  string(mean(mcc)) *\"\\n\")\n",
    "end;\n",
    "#println(\"Accuracy\", \"   Precision\", \"   npv\",\" recall\", \"    specifity\", \"     mcc\", \"       f1\")\n",
    "#(hcat(accuracy, precision, npv, recall, specifity, mcc, f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
