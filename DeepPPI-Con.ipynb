{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in (\"Knet\", \"Plots\", \"NBInclude\")\n",
    "    Pkg.installed(p) == nothing && Pkg.add(p);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet, Plots, NBInclude;\n",
    "nbinclude(\"deepppiutils.ipynb\"); # loads trnper, devper, tstper, featuresDict, concatAB, train!, trainSep!, modelevaluation \n",
    "                                 # ygold, winit, minibatchi, predict, predictSep,loss,zeroone, report, lossgradient, params,\n",
    "                                 # loadmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of hidden units in the hidden layers of the DeepPPI-CON model\n",
    "HIDDENS = Any[NOCONCAT, 512, 256, 128, 128, NOOUTPUTS]; \n",
    "NOEPOCH = 30;\n",
    "BATCHSIZE = 64;\n",
    "PDROP = (0, 0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(:epoch, 10, :trn, 0.8327466475095785, :dev, 0.8095933787561146)\n",
      "(:epoch, 20, :trn, 0.9761880055342699, :dev, 0.9027690426275332)\n",
      "(:epoch, 30, :trn, 0.9845213388676032, :dev, 0.9048087002096435)\n",
      "110.582605 seconds (70.33 M allocations: 2.425 GiB, 6.38% gc time)\n",
      "Dataset1\n",
      "Training: min. loss =0.0248191, min. error =0.008688537675606622\n",
      "Test: min. loss =0.35022405, min. error =0.09310796645702313\n",
      "TP: 3837 , TN: 3989 , FP: 450 , FN: 353\n",
      "Model evaluation:\n",
      "Accuracy : 0.9069417081933017\n",
      "Precision : 0.8950314905528342\n",
      "NPV : 0.9187010592080375\n",
      "Sensitivity / Recall : 0.9157517899761336\n",
      "Specifity : 0.8986258166253661\n",
      "MCC : 0.8140550143941774\n",
      "F1 : 0.9052730917889261\n",
      "(:epoch, 10, :trn, 0.7378365793954875, :dev, 0.7256376659678546)\n",
      "(:epoch, 20, :trn, 0.9764274691358025, :dev, 0.9009171907756814)\n",
      "(:epoch, 30, :trn, 0.9929012345679012, :dev, 0.9100847309573724)\n",
      "108.301782 seconds (69.81 M allocations: 2.390 GiB, 7.18% gc time)\n",
      "Dataset2\n",
      "Training: min. loss =0.019443903, min. error =0.0064429012345679215\n",
      "Test: min. loss =0.39985242, min. error =0.08884958071278826\n",
      "TP: 3796 , TN: 4067 , FP: 439 , FN: 327\n",
      "Model evaluation:\n",
      "Accuracy : 0.9112295746899989\n",
      "Precision : 0.8963400236127509\n",
      "NPV : 0.9255803366122939\n",
      "Sensitivity / Recall : 0.9206888188212466\n",
      "Specifity : 0.9025743453173546\n",
      "MCC : 0.8225914882870032\n",
      "F1 : 0.9083512801018961\n",
      "(:epoch, 10, :trn, 0.8554464665815241, :dev, 0.8342068483577917)\n",
      "(:epoch, 20, :trn, 0.9710262345679013, :dev, 0.8988862683438155)\n",
      "(:epoch, 30, :trn, 0.9869598765432098, :dev, 0.9072196016771488)\n",
      "123.716055 seconds (69.03 M allocations: 2.366 GiB, 0.59% gc time)\n",
      "Dataset3\n",
      "Training: min. loss =0.022195105, min. error =0.008024691358024638\n",
      "Test: min. loss =0.3992951, min. error =0.09134346610761712\n",
      "TP: 3862 , TN: 3978 , FP: 462 , FN: 327\n",
      "Model evaluation:\n",
      "Accuracy : 0.908564144165025\n",
      "Precision : 0.893154486586494\n",
      "NPV : 0.924041811632046\n",
      "Sensitivity / Recall : 0.9219384101217475\n",
      "Specifity : 0.8959459459459459\n",
      "MCC : 0.8175402548651212\n",
      "F1 : 0.9073182190875932\n",
      "(:epoch, 10, :trn, 0.850585355470413, :dev, 0.8207525331935709)\n",
      "(:epoch, 20, :trn, 0.9740275117071094, :dev, 0.8948309748427673)\n",
      "(:epoch, 30, :trn, 0.9843364197530864, :dev, 0.9010329315164222)\n",
      "103.723400 seconds (69.79 M allocations: 2.390 GiB, 1.30% gc time)\n",
      "Dataset4\n",
      "Training: min. loss =0.03228648, min. error =0.011350574712643668\n",
      "Test: min. loss =0.4008119, min. error =0.09370632424877712\n",
      "TP: 3962 , TN: 3858 , FP: 342 , FN: 467\n",
      "Model evaluation:\n",
      "Accuracy : 0.9062463784911345\n",
      "Precision : 0.9205390334572491\n",
      "NPV : 0.892023121181035\n",
      "Sensitivity / Recall : 0.8945585911040868\n",
      "Specifity : 0.9185714285714286\n",
      "MCC : 0.8128460376703043\n",
      "F1 : 0.9073628763417654\n",
      "(:epoch, 10, :trn, 0.7715184653043848, :dev, 0.7517470300489169)\n",
      "(:epoch, 20, :trn, 0.9736882716049383, :dev, 0.8984429594689028)\n",
      "(:epoch, 30, :trn, 0.9938657407407407, :dev, 0.9118929070580014)\n",
      "118.305687 seconds (69.46 M allocations: 2.380 GiB, 0.93% gc time)\n",
      "Dataset5\n",
      "Training: min. loss =0.020207327, min. error =0.0064429012345679215\n",
      "Test: min. loss =0.38272542, min. error =0.09169505590496152\n",
      "TP: 3824 , TN: 4014 , FP: 441 , FN: 350\n",
      "Model evaluation:\n",
      "Accuracy : 0.9083323675976359\n",
      "Precision : 0.8966002344665885\n",
      "NPV : 0.9197983499267189\n",
      "Sensitivity / Recall : 0.9161475802587447\n",
      "Specifity : 0.901010101010101\n",
      "MCC : 0.8167780447503686\n",
      "F1 : 0.9062685151195321\n"
     ]
    }
   ],
   "source": [
    "accuracy =[]\n",
    "recall=[]\n",
    "specifity=[]\n",
    "precision= []\n",
    "mcc=[]\n",
    "f1=[]\n",
    "npv=[]\n",
    "accuracyt= recalli=specifityi=precisioni=mcci = 0.0\n",
    "for i in 1:5\n",
    "    #setseed(i);\n",
    "    w = winit(HIDDENS...);\n",
    "    \n",
    "    #dtrn, ddev, dtst = dividedataset(concatAB, ygold, trnper, devper, tstper; batchsize= BATCHSIZE);\n",
    "    dtrn, ddev = dividedataset(concatAB, ygold, trnper, devper, tstper; batchsize= BATCHSIZE);\n",
    "    \n",
    "    optims = params(w; optim=\"Momentum\", lr=0.01, gamma=0.9);\n",
    "    #@time trnloss, trnerr, tstloss, tsterr=trainSep!(w, optims, dtrn, predictSep, ddev; pdrop=PDROP, epochs=NOEPOCH) \n",
    "    @time train!(w, optims, dtrn, predict, ddev; pdrop=PDROP, epochs=NOEPOCH) \n",
    "    #trainSep!(w, optims, dtrn, predictSep, ddev; pdrop=PDROP, epochs=NOEPOCH) \n",
    "    \n",
    "    println(\"Dataset\", i)\n",
    "    println(\"Training: min. loss =\",loss(w,dtrn,predict),\", min. error =\",zeroone(w,dtrn,predict))  \n",
    "    println(\"Test: min. loss =\",loss(w,ddev,predict),\", min. error =\",zeroone(w,ddev,predict))  \n",
    "    \n",
    "    accuracyt,recalli,specifityi,precisioni,mcci,f1i,npvi = modelevaluation(w, ddev, predict; p=true);\n",
    "    push!(accuracy, accuracyt)\n",
    "    push!(recall, recalli)\n",
    "    push!(specifity, specifityi)\n",
    "    push!(precision, precisioni)\n",
    "    push!(mcc, mcci)\n",
    "    push!(f1, f1i)\n",
    "    push!(npv, npvi)\n",
    "    \n",
    "    writedlm(\"DeepPPI_ConModel\"*string(i)*\".csv\", map(Array, w))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(accuracy)\n",
    "open(\"DeepPPI-Con_Scores.txt\", \"w\") do f\n",
    "    write(f, \"Dataset \\tAccuracy\\t\\t\\tPrecision\\t\\t\\tnpv      \\t\\t\\tRecall   \\t\\t\\tSpecifity\\t\\t\\tMCC\\n\")\n",
    "    write(f, \"__________________________________________________________________________________________________________________________________\\n\")\n",
    "    for i in 1:5\n",
    "        write(f, \"dataset\"*string(i)*\"\\t\"*string(accuracy[i]) *\"\\t\"* string(precision[i]) *\"\\t\"* string(npv[i]) *\"\\t\"* string(recall[i]) *\"\\t\"*  string(specifity[i]) *\"\\t\"*  string(mcc[i]) *\"\\n\")\n",
    "    end\n",
    "    write(f, \"__________________________________________________________________________________________________________________________________\\n\")\n",
    "    write(f, \"Average\"*\"\\t\\t\"*string(mean(accuracy)) *\"\\t\"* string(mean(precision))  *\"\\t\"* string(mean(npv)) *\"\\t\"* string(mean(recall)) *\"\\t\"*  string(mean(specifity)) *\"\\t\"*  string(mean(mcc)) *\"\\n\")\n",
    "end;\n",
    "#println(\"Accuracy\", \"   Precision\", \"   npv\",\" recall\", \"    specifity\", \"     mcc\", \"       f1\")\n",
    "#(hcat(accuracy, precision, npv, recall, specifity, mcc, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of trainable parameters: 777474\n"
     ]
    }
   ],
   "source": [
    "w_sizes = Tuple{Int64,Int64}[(512, 1164) (512, 1) (256, 512) (256, 1) (128, 256) (128, 1) (128, 128) (128, 1) (2, 128) (2, 1)]\n",
    "totalNoOfParams = 0;\n",
    "for i in 1:length(w_sizes)\n",
    "    totalNoOfParams += w_sizes[i][1] * w_sizes[i][2]\n",
    "end\n",
    "println(\"Total Number of trainable parameters: \", totalNoOfParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following code is used while training to test different hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot([vcat(trnloss) vcat(tstloss)],ylim=(0.0,0.8), labels=[:trnMulti :trnloss_01 :trnloss_001 :trnloss_005 :tstMulti :tstloss_01 :tstloss_001 :tstloss_005],xlabel=\"Epochs\",ylabel=\"Loss\")  \n",
    "#plot([vcat(trnloss)],ylim=(0.2,0.7),labels=[:trnMulti],xlabel=\"Epochs\",ylabel=\"Loss\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([vcat(trnerr) vcat(tsterr)],ylim=(0.0,0.5), labels=[:trnMulti_1 :trnMulti_01 :trnMulti_001 :trnMulti_005 :tstMulti_1 :tstMulti_01 :tstMulti_001 :trnMulti_005],xlabel=\"Epochs\",ylabel=\"Error\")  \n",
    "#plot([vcat(trnerr)],ylim=(0.05,0.45), labels=[:trnMulti],xlabel=\"Epochs\",ylabel=\"Error\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "trnacc = 0;\n",
    "for (x, y) in dtrn\n",
    "    ypred = predict(w,x)\n",
    "    trnacc += accuracyi(ypred, y) \n",
    "end\n",
    "print(trnacc/length(dtrn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set\n",
    "tstacc = 0;\n",
    "for (x, y) in dtst\n",
    "    ypred = predict(w,x)\n",
    "    tstacc += accuracyi(ypred, y) \n",
    "end\n",
    "print(tstacc/length(dtst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev Set\n",
    "devacc = 0;\n",
    "for (x, y) in ddev\n",
    "    ypred = predict(w,x)\n",
    "    devacc += accuracyi(ypred, y) \n",
    "end\n",
    "print(devacc/length(ddev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
