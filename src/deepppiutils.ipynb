{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Knet;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Dictionary Construction\n",
    "\n",
    "This function constructs protein features dictionary. Protein features for the taining data set are stored in the file \"yeast_feature_all.csv\". \n",
    "The function returns a dictionary mapping a protein UniProt ID to its 1164-features vector\n",
    "* ```featuresDict```    : The features dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function constructFeatDict()\n",
    "    # read features for all proteins\n",
    "    f = open(\"yeast_feature_all.csv\");\n",
    "    lines = readlines(f);\n",
    "    close(f);\n",
    "    numberOfProteins = length(lines) \n",
    "    featureNames = String.(split(lines[1],\",\")); \n",
    "    d = length(featureNames) - 1 # number of features per protein\n",
    "    proteins = lines[2:numberOfProteins];\n",
    "    featuresDict = Dict{String,Any}()\n",
    "    for p in proteins\n",
    "        featureVect = String.(split(p, \",\"));\n",
    "        featuresDict[featureVect[1]] = parse.(Float32, featureVect[2:d+1]) # featureVect[1] is the protein UniProt ID \n",
    "    end\n",
    "    return featuresDict;\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function constructFeatDictNegatome()\n",
    "    # read features for all proteins\n",
    "    f = open(\"yeast_feature_all.csv\");\n",
    "    lines = readlines(f);\n",
    "    close(f);\n",
    "    numberOfProteins = length(lines) \n",
    "    featureNames = String.(split(lines[1],\",\")); \n",
    "    d = length(featureNames) - 1 # number of features per protein\n",
    "    proteins = lines[2:numberOfProteins];\n",
    "    featuresDict = Dict{String,Any}()\n",
    "    for p in proteins\n",
    "        featureVect = String.(split(p, \",\"));\n",
    "        featuresDict[featureVect[1]] = parse.(Float32, featureVect[2:d+1]) # featureVect[1] is the protein UniProt ID \n",
    "    end\n",
    "    f = open(\"test_datasets/Negatome_features.csv\");\n",
    "    lines = readlines(f);\n",
    "    close(f);\n",
    "    numberOfProteins = length(lines) \n",
    "    featureNames = String.(split(lines[1],\",\")); \n",
    "    d = length(featureNames) - 1 # number of features per protein\n",
    "    proteins = lines[2:numberOfProteins];\n",
    "    for p in proteins\n",
    "        featureVect = String.(split(p, \",\"));\n",
    "        if(\"\" in featureVect[2:d+1])\n",
    "            continue\n",
    "        end\n",
    "        featuresDict[featureVect[1]] = parse.(Float32, featureVect[2:d+1]) # featureVect[1] is the protein UniProt ID \n",
    "    end\n",
    "    return featuresDict;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "This function loads the training data with its labels \n",
    "* ```featuresDict```    : The features dictionary which maps the protein ID to its features vector\n",
    "\n",
    "The function returns two arrays, the data and the labels. \n",
    "In order to construct the data matrix, the following steps are executed:\n",
    "* Protein pairs (represented by their UniProt IDs are read from the file \"yeast_protein_pair.csv\".\n",
    "* A feature vector for each partner in the protein pair is extracted from ```featuresDict``` \n",
    "* The resulting two feature vectors are concatenated to form a new combined 2328-elements features vector\n",
    "* Combined vectors for all pairs in the dataset are concatenated vertically to for the 65852x2328 data matrix ```concatAB```. \n",
    "* Labels for the protein pairs are read and returned as ```ygold```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function loaddata(featuresDict)\n",
    "    f = open(\"yeast_protein_pair.csv\")\n",
    "    lines = readlines(f);\n",
    "    close(f)\n",
    "    n = length(lines); # number of samples/ protein pairs\n",
    "    samples = lines[2:end - 1];\n",
    "    concatAB1 = []\n",
    "    ygold = Array{UInt8,1}(length(samples));\n",
    "    i = 1;\n",
    "    for s in samples\n",
    "        s = String.(split(s, \",\"));\n",
    "        push!(concatAB1, hcat(reshape(mat(featuresDict[s[1]]), 1, 1164), reshape(mat(featuresDict[s[2]]), 1, 1164)))\n",
    "        label = parse(Int64, s[3]);\n",
    "        ygold[i] = convert(UInt8, label + 1);\n",
    "        i += 1;\n",
    "    end\n",
    "    concatAB = vcat(map(Atype, concatAB1)...)\n",
    "    return concatAB, ygold\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function loaddataNegatome(featuresDict)\n",
    "    f = open(\"yeast_protein_pair.csv\")\n",
    "    lines = readlines(f);\n",
    "    close(f)\n",
    "    f = open(\"test_datasets/Negatome_pairs.csv\")\n",
    "    negsamples = readlines(f);\n",
    "    close(f)\n",
    "    n = length(lines); # number of samples/ protein pairs\n",
    "    samples = lines[2:end - 1];\n",
    "    possamples = samples[1:17257]\n",
    "    concatAB1 = []\n",
    "    ygold = Array{UInt8,1}(length(possamples) + length(negsamples));\n",
    "    i = 1;\n",
    "    for s in possamples\n",
    "        s = String.(split(s, \",\"));\n",
    "        push!(concatAB1, hcat(reshape(mat(featuresDict[s[1]]), 1, 1164), reshape(mat(featuresDict[s[2]]), 1, 1164)))\n",
    "        ygold[i] = 0x02;\n",
    "        i += 1;\n",
    "    end\n",
    "    \n",
    "    \n",
    "    n = length(negsamples); # number of samples/ protein pairs\n",
    "    for s in negsamples\n",
    "        s = String.(split(s, \"\\t\"));\n",
    "        if s[1] in keys(featuresDict) && s[2] in keys(featuresDict) \n",
    "            push!(concatAB1, hcat(reshape(mat(featuresDict[s[1]]), 1, 1164), reshape(mat(featuresDict[s[2]]), 1, 1164)))\n",
    "            ygold[i] = 0x01;\n",
    "            i += 1;\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    concatAB = vcat(map(Atype, concatAB1)...)\n",
    "    return concatAB, ygold\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the model\n",
    "\n",
    "This function initializes weights and bias for the model.\n",
    "* ```h...```    : elements representing the number of inputs to the NN, the number of hidden units in each hidden layer and finally the number of outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function winit(h...)\n",
    "    w = Any[]\n",
    "    for i=2:length(h)\n",
    "        push!(w, 0.01*randn(h[i],h[i-1]))\n",
    "        push!(w, zeros(h[i],1))\n",
    "    end\n",
    "    map(Atype, w)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing trn/dev/tst datasets\n",
    "This function divides the total datset into trn/dev/tst sets using the ```trnper```, ```devper```, ```tstper```percentages. Before division, the negative subset to be used is picked randomly from the negative dataset to preserve a 1:1 positive:negative ratio.\n",
    "\n",
    "* ```data```    : data matrix where each row represents a sample in the dataset\n",
    "* ```ygold```    : labels of the dataset where 0x01 means the protein pair do not interact and 0x02 mean the pair interacts. \n",
    "* ```trnper```    : the percentage of the total dataset to be considered as training set\n",
    "* ```devper```    : the percentage of the total dataset to be considered as development set\n",
    "* ```tstper```    : the percentage of the total dataset to be considered as test set \n",
    "* ```batchsize``` : the number of samples to put in a minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function dividedataset(data, ygold, trnper, devper, tstper; batchsize=64, dev=true) # 0.58, 0.17, 0.25\n",
    "    nopos = 17257 # number of total positive samples\n",
    "    \n",
    "    # construct a 1:1 ratio of positive and negative samples as the data set\n",
    "    posdata = data[1 : nopos, :];\n",
    "    posygold = ygold[1 : nopos];\n",
    "    negdata = data[nopos + 1 : end, :];\n",
    "    negygold = ygold[nopos + 1 : end];\n",
    "    \n",
    "    # pick nopos negative samples randomly\n",
    "    indneg = randperm(nopos)\n",
    "    data = vcat(posdata, negdata[indneg[1:end],:])\n",
    "    ygold = vcat(posygold, negygold[indneg[1:end]])\n",
    "    \n",
    "    nosamples = size(data,1)\n",
    "    notst = Int(floor(tstper * nosamples))\n",
    "    notrn = Int(floor(trnper * nosamples))\n",
    "    nodev = nosamples - notrn - notst\n",
    "    ind = randperm(nosamples)\n",
    "    \n",
    "    xtrn = data[ind[1:notrn],:];\n",
    "    ytrn = ygold[ind[1:notrn]];\n",
    "    \n",
    "    xtst = data[ind[notrn+1:notrn+notst], :];\n",
    "    ytst = ygold[ind[notrn+1:notrn+notst]];\n",
    "    \n",
    "    dtrn = minibatchi(xtrn',ytrn,batchsize);\n",
    "    dtst = minibatchi(xtst',ytst,batchsize);\n",
    "    \n",
    "    if (dev)\n",
    "        xdev = data[ind[notrn+1:notrn+nodev], :];\n",
    "        ydev = ygold[ind[notrn+1:notrn+nodev]];\n",
    "        ddev = minibatchi(xdev',ydev,batchsize);\n",
    "        return dtrn, ddev, dtst\n",
    "    else\n",
    "        return dtrn, dtst\n",
    "    end\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function dividedatasetNegatome(data, ygold, trnper, devper, tstper; batchsize=64, dev=true) # 0.58, 0.17, 0.25\n",
    "    nopos = 17257 # number of total positive samples\n",
    "    noneg = 6222\n",
    "    # construct a 1:1 ratio of positive and negative samples as the data set\n",
    "    posdata = data[1 : nopos, :];\n",
    "    posygold = ygold[1 : nopos];\n",
    "    negdata = data[nopos + 1 : end, :];\n",
    "    negygold = ygold[nopos + 1 : end];\n",
    "    \n",
    "    # pick noneg positive samples randomly\n",
    "    indneg = randperm(noneg)\n",
    "    data = vcat(posdata[indneg[1:end],:], negdata)\n",
    "    ygold = vcat(posygold[indneg[1:end]], negygold)\n",
    "    println(summary(data))\n",
    "    nosamples = size(data,1)\n",
    "    notst = Int(floor(tstper * nosamples))\n",
    "    notrn = Int(floor(trnper * nosamples))\n",
    "    nodev = nosamples - notrn - notst\n",
    "    ind = randperm(nosamples)\n",
    "    \n",
    "    xtrn = data[ind[1:notrn],:];\n",
    "    ytrn = ygold[ind[1:notrn]];\n",
    "    \n",
    "    xtst = data[ind[notrn+1:notrn+notst], :];\n",
    "    ytst = ygold[ind[notrn+1:notrn+notst]];\n",
    "    \n",
    "    dtrn = minibatchi(xtrn',ytrn,batchsize);\n",
    "    dtst = minibatchi(xtst',ytst,batchsize);\n",
    "    \n",
    "    if (dev)\n",
    "        xdev = data[ind[notrn+1:notrn+nodev], :];\n",
    "        ydev = ygold[ind[notrn+1:notrn+nodev]];\n",
    "        ddev = minibatchi(xdev',ydev,batchsize);\n",
    "        return dtrn, ddev, dtst\n",
    "    else\n",
    "        return dtrn, dtst\n",
    "    end\n",
    "    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function trn_tst_split(data, ygold, trnper, tstper; batchsize=64)\n",
    "    nosamples = size(data,1)\n",
    "    notrn = Int(floor(trnper * nosamples))\n",
    "    notst = nosamples - notrn\n",
    "    ind = randperm(nosamples)\n",
    "    \n",
    "    xtrn = data[ind[1:notrn],:];\n",
    "    ytrn = ygold[ind[1:notrn]];\n",
    "    \n",
    "    xtst = data[ind[notrn+1:notrn+notst], :];\n",
    "    ytst = ygold[ind[notrn+1:notrn+notst]];\n",
    "    \n",
    "    dtrn = minibatchi(xtrn',ytrn,batchsize);\n",
    "    dtst = minibatchi(xtst',ytst,batchsize);\n",
    "    \n",
    "    return dtrn, dtst\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Forward Pass function\n",
    "```predict``` function represents the forward pass of the MLP and is used to train DeepPPI-Con model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function predict(w,x; pdrop=(0,0))\n",
    "    for i=1:2:length(w)\n",
    "        x = dropout(x, pdrop[i==1 || i == length(w)-1?1:2])\n",
    "        x = w[i]*x .+ w[i+1]\n",
    "        if i < length(w)-1\n",
    "            x = relu.(x)   ## apply RELU to all but the final layer's output                        \n",
    "        end\n",
    "    end\n",
    "    return x\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```predictSep``` function represents the forward pass of the MLP and is used to train DeepPPI-Sep model\n",
    "The data is first divided into a matrix ```xa``` having the features of the first partner in each protein pair from the total data set and another matrix ```xb``` containing the features of the second partner\n",
    "Each of both matrices is input seperately into an MLP with seperate weights.\n",
    "The output of both networks is then concatenated and input into another network which finally outputs a 2-D vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function predictSep(w, x; pdrop=(0,0), nofeat=1164)\n",
    "    wa = w[1:6]\n",
    "    wb = w[7:12]\n",
    "    wm = w[13:end]\n",
    "    xa = x[1:nofeat,:]\n",
    "    xb = x[nofeat+1:end,:]\n",
    "    \n",
    "    for i=1:2:length(wa)\n",
    "        xa = dropout(xa, pdrop[i==1?1:2])\n",
    "        xa = wa[i]*xa .+ wa[i+1]\n",
    "        xa = relu.(xa)                      \n",
    "    end\n",
    "    \n",
    "    for i=1:2:length(wb)\n",
    "        xb = dropout(xb, pdrop[i==1?1:2])\n",
    "        xb = wb[i]*xb .+ wb[i+1]\n",
    "        xb = relu.(xb)                         \n",
    "    end\n",
    "    \n",
    "    xm = vcat(xa, xb)\n",
    "    \n",
    "    for i=1:2:length(wm)\n",
    "        xm = dropout(xm, pdrop[i==1?2:1])\n",
    "        xm = wm[i]*xm .+ wm[i+1]\n",
    "        if i<length(wm)-1\n",
    "            xm = relu.(xm)   ## apply RELU to all but the final layer's output                        \n",
    "        end\n",
    "    end\n",
    "    return xm\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss(w,x,ygold, predict; o...) = nll(predict(w,x; o...),ygold);\n",
    "loss(w, data, predict; o...) = mean(loss(w,x,y,predict; o...) for (x,y) in data);\n",
    "zeroone(w,data,predict; o...) = 1 - accuracyi(w,data,predict);\n",
    "lossgradient = grad(loss);\n",
    "report(epoch)=println((:epoch,epoch,:trn,accuracyi(w,dtrn,predict),:dev,accuracyi(w,ddev,predict)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training \n",
    "```train!``` function trains the model(w) with the optimizer(s) specified in ```optims``` and returns lists containing error and loss values for both trn and dev/tst datasets **note that this is commented out for model evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function train!(w, optims,data,predict, ddev; epochs=100,lr=.5,o...)\n",
    "    patience = 0\n",
    "    bestscore = Inf\n",
    "    bestw = Any[]\n",
    "    bestep = 0\n",
    "    #trnloss = Any[loss(w,data,predict)]\n",
    "    #trnerr = Any[zeroone(w,data,predict)]\n",
    "    #devloss = Any[loss(w,ddev,predict)]\n",
    "    deverr = Any[zeroone(w,ddev,predict)]\n",
    "    for epoch in 1:epochs\n",
    "        if patience > 10\n",
    "          print(\"Early stopping no progess for 10 epoch... with best score: \"*string(bestscore)*\" during epoch: \"*string(bestep)*\"\\n\")\n",
    "          break\n",
    "        end\n",
    "        if(epoch % 10 == 0)\n",
    "            println((:epoch,epoch,:trn,accuracyi(w,data,predict),:tst,accuracyi(w,ddev,predict)));\n",
    "        end\n",
    "        for (x,y) in data\n",
    "            dw = lossgradient(w,x,y, predict; o...)\n",
    "            #@show (map(vecnorm, dw))\n",
    "            update!(w, dw, optims)\n",
    "#             for i in 1:length(w)\n",
    "#                w[i] -= lr * dw[i]\n",
    "#             end\n",
    "        end\n",
    "        #push!(trnloss, loss(w,data,predict))\n",
    "        #push!(trnerr, zeroone(w,data,predict))\n",
    "        #push!(devloss, loss(w,ddev,predict))\n",
    "        deverror = zeroone(w,ddev,predict)\n",
    "        push!(deverr, deverror)\n",
    "        if deverror < bestscore\n",
    "          bestw = deepcopy(w)\n",
    "          bestscore = deverror\n",
    "          bestep = epoch\n",
    "          patience = 0\n",
    "        else\n",
    "          patience += 1\n",
    "        end\n",
    "    end\n",
    "    w = deepcopy(bestw)\n",
    "    #return trnloss, trnerr , devloss, deverr\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train model(w) with SGD and return a list containing w for every epoch\n",
    "function trainSep!(w, optims,data,predict, ddev; epochs=100,lr=.01,o...) #, decay=1.0\n",
    "    patience = 0\n",
    "    bestscore = Inf\n",
    "    bestw = Any[]\n",
    "    bestep = 0\n",
    "    #trnloss = Any[loss(w,data,predict)]\n",
    "    #trnerr = Any[zeroone(w,data,predict)]\n",
    "    #devloss = Any[loss(w,ddev,predict)]\n",
    "    deverr = Any[zeroone(w,ddev,predict)]\n",
    "    for epoch in 1:epochs\n",
    "        if patience > 10\n",
    "          print(\"Early stopping no progess for 10 epoch... with best score: \"*string(bestscore)*\"\\n\")\n",
    "          break\n",
    "        end\n",
    "        for (x,y) in data\n",
    "            dw = lossgradient(w,x,y, predict; o...)\n",
    "            #@show (map(vecnorm, dw))\n",
    "            update!(w, dw, optims)\n",
    "        end\n",
    "        #push!(trnloss, loss(w,data,predict))\n",
    "        #push!(trnerr, zeroone(w,data,predict))\n",
    "        #push!(devloss, loss(w,ddev,predict))\n",
    "        deverror = zeroone(w,ddev,predict)\n",
    "        push!(deverr, deverror)\n",
    "        if deverror < bestscore\n",
    "          bestw = deepcopy(w)\n",
    "          bestscore = deverror\n",
    "          bestep = epoch\n",
    "          patience = 0\n",
    "        else\n",
    "          patience += 1\n",
    "        end\n",
    "        if(epoch % 10 == 0)\n",
    "            println((:epoch,epoch,:trn,accuracyi(w,data,predict),:tst,accuracyi(w,ddev,predict)));\n",
    "        end\n",
    "    end\n",
    "    w = deepcopy(bestw)\n",
    "    #return trnloss, trnerr, devloss, deverr\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimzation methods\n",
    "This function constructs an optimizer object ```prms``` for a weight array ```ws``` using the passed optimization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates necessary parameters for each weight to use in the optimization\n",
    "function params(ws; optim=\"Sgd\", lr=0.01, gamma=0.95, eps=1e-6, rho=0.9, beta1=0.9, beta2=0.95)\n",
    "    prms = Any[]\n",
    "\n",
    "    for i=1:length(ws)\n",
    "        w = ws[i]\n",
    "        if optim == \"Sgd\"\n",
    "            prm = Sgd(;lr=lr)\n",
    "        elseif optim == \"Momentum\"\n",
    "            prm = Momentum(lr=lr, gamma=gamma)\n",
    "        elseif optim == \"Nesterov\"\n",
    "            prm = Nesterov(lr=lr, gamma=gamma)\n",
    "        elseif optim == \"Adagrad\"\n",
    "            prm = Adagrad(lr=lr, eps=eps)\n",
    "        elseif optim == \"Adadelta\"\n",
    "            prm = Adadelta(lr=lr, rho=rho, eps=eps)\n",
    "        elseif optim == \"Rmsprop\"\n",
    "            prm = Rmsprop(lr=lr, rho=rho, eps=eps)\n",
    "        elseif optim == \"Adam\"\n",
    "            prm = Adam(lr=lr, beta1=beta1, beta2=beta2, eps=eps)\n",
    "        else\n",
    "            error(\"Unknown optimization method!\")\n",
    "        end\n",
    "        push!(prms, prm)\n",
    "    end\n",
    "\n",
    "    return prms\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics\n",
    "## Accuracy\n",
    "This function calculates the accuracy of the predections produced by a model by the following formula:\n",
    "\n",
    "```Accuracy = (number of correct predection)/(number of samples)```\n",
    "\n",
    "**accuracyi(ypred, ygold)**\n",
    "\n",
    "* ```ypred```    : predections produced by the models, for each samples a 2 dimensional one-hot vector is used, (1,0; i.e. if the value of the first element is higher thean the second) means no interaction while (0,1) means an interaction is predicted. \n",
    "* ```ygold```    : labels of the dataset where 0x01 means the protein pair do not interact and 0x02 mean the pair interacts.\n",
    "\n",
    "**accuracyi(w, data, predict)**\n",
    "\n",
    "This function returns an average accuracy over all minibatches\n",
    "* ```w```    : model weights\n",
    "* ```data```    : minibatched dataset containing both data and labels\n",
    "* ```predict```    : the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function accuracyi(ypred, ygold)\n",
    "    count = 0\n",
    "    for i in 1:size(ypred, 2)\n",
    "        if((ypred[1,i] >= ypred[2,i] && ygold[i]==1) || (ypred[1,i] <= ypred[2,i] && ygold[i]==2))\n",
    "            count +=1\n",
    "        end\n",
    "    end\n",
    "    return count/size(ypred, 2);\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function accuracyi(w, data, predict)\n",
    "    acc = 0;\n",
    "    for (x, y) in data\n",
    "        ypred = predict(w,x)\n",
    "        acc += accuracyi(ypred, y) \n",
    "    end\n",
    "    return acc/length(data)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other performance metrics\n",
    "This function caculates and returns the following performance metrics\n",
    "\n",
    "* ```Accuracy``` = (tp + tn) / (tp + tn + fn + fp)\n",
    "* ```Recall``` = tp / (tp + fn)\n",
    "* ```Specifity``` = tn / (tn + fp)\n",
    "* ```Precision``` = tp / (tp + fp)\n",
    "* ```MCC``` = (tp.tn-fp.fn)/(sqrt((tp+fp)(tp+fn)(tn+fp)(tn+fn)))\n",
    "* ```F1``` : A statistical measure of the test accuracy which is the weighted average of precision and recall\n",
    "\n",
    "$$f1 = (2tp)/(2tp+fp+fn)$$\n",
    "* ```NPV``` : Negative predictive value (NPV) = Σ True negative/ Σ Predicted negatives\n",
    "\n",
    "$$npv = (tn)/(tn + fn)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function modelevaluation(w, data, pred; p=false)\n",
    "    tp=tn=fp=fn= 0    \n",
    "\n",
    "    for (x,y) in data\n",
    "        ypred = pred(w, x)\n",
    "        for i in 1:size(ypred, 2)\n",
    "            if(ypred[1,i] >= ypred[2,i] && y[i]==1)\n",
    "                tn += 1;\n",
    "            elseif(ypred[1,i] <= ypred[2,i] && y[i]==2)\n",
    "                tp += 1\n",
    "            elseif(ypred[1,i] >= ypred[2,i] && y[i]==2)\n",
    "                fp += 1\n",
    "            else\n",
    "                fn += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    accuracy = (tp + tn) / (tp + tn + fn + fp+1e-06)\n",
    "    recall = tp / (tp + fn +1e-06)\n",
    "    specifity = tn / (tn + fp+1e-06)\n",
    "    precision = tp / (tp + fp +1e-06)\n",
    "    mcc = (tp*tn-fp*fn)/(sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))+1e-06)\n",
    "    f1 = (tp*2)/(tp*2+fp+fn+1e-06)\n",
    "    npv = (tn)/(tn + fn + 1e-06)\n",
    "    if (p)\n",
    "        println(\"TP: \", tp, \" , TN: \", tn, \" , FP: \", fp, \" , FN: \", fn);\n",
    "        println(\"Model evaluation:\");\n",
    "        println(\"Accuracy : \", accuracy);\n",
    "        println(\"Precision : \", precision);\n",
    "        println(\"NPV : \", npv);\n",
    "        println(\"Sensitivity / Recall : \", recall);\n",
    "        println(\"Specifity : \", specifity);\n",
    "        println(\"MCC : \", mcc);\n",
    "        println(\"F1 : \", f1);\n",
    "    end\n",
    "    \n",
    "    return accuracy,recall,specifity,precision,mcc,f1,npv;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Minibatching & Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input X matrix and gold labels Y\n",
    "# Output list of minibatches (x, y)\n",
    "function minibatchi(X, Y, batchsize)\n",
    "    data = Any[] \n",
    "    meanx = mean(X,2);\n",
    "    if(gpu() < 0)\n",
    "        # CPU\n",
    "        stdx=std(X,2);\n",
    "    else\n",
    "        # for GPU, manually calculate std for Knet arrays\n",
    "        stdx= sqrt.(sum(abs2.(X.-meanx), 2)/(size(X,2) - 1));\n",
    "    end\n",
    "    X = (X.-meanx) ./ stdx;\n",
    "\n",
    "    for i = 1:batchsize:size(X, 2)\n",
    "        bl = min(i + batchsize - 1, size(X, 2))\n",
    "        push!(data, (X[:, i:bl], Y[i:bl]))\n",
    "    end\n",
    "    return data\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model\n",
    "This function is used to load the parameters of a pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function loadmodel(filename,  w_sizes; Atype=gpu() >= 0 ? KnetArray{Float32} : Array{Float32})\n",
    "    ## weight sizes of DeepPPI-Sep model\n",
    "    # w_sizes = Tuple{Int64,Int64}[(512, 1164) (512, 1) (256, 512) (256, 1) (128, 256) (128, 1) (512, 1164) (512, 1) (256, 512) (256, 1) (128, 256) (128, 1) (128, 256) (128, 1) (2, 128) (2, 1)]\n",
    "    ## weight sizes of DeepPPI-Con model\n",
    "    # w_sizes = Tuple{Int64,Int64}[(512, 1164) (512, 1) (256, 512) (256, 1) (128, 256) (128, 1) (128, 128) (128, 1) (2, 128) (2, 1)]\n",
    "    temp = readdlm(filename);\n",
    "    w = Any[]\n",
    "    for i in 1:size(temp, 1)\n",
    "        temp1 = reshape(temp[i, 1:w_sizes[i][1]*w_sizes[i][2]], w_sizes[i])\n",
    "        push!(w, temp1)\n",
    "    end\n",
    "    w = map(Atype, w)\n",
    "    return w\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Atype = gpu() >= 0 ? KnetArray{Float32} : Array{Float32};\n",
    "setseed(1);\n",
    "\n",
    "# number of input features per protein\n",
    "NOINPUTS = 1164;\n",
    "# number of input features for the protein pair\n",
    "NOCONCAT = NOINPUTS * 2;\n",
    "# output is a one-hot-vector 10 -> not interacting, 01 -> intracting\n",
    "NOOUTPUTS = 2;\n",
    "\n",
    "# the percentages used for evaluationg models in the paper\n",
    "trnper = 0.75;\n",
    "tstper = 0.25;\n",
    "devper = 1 - trnper - tstper;\n",
    "\n",
    "# the percentages used during training and model analysis\n",
    "#trnper = 0.58;\n",
    "#devper = 0.17;\n",
    "#tstper = 1 - trnper - devper;\n",
    "\n",
    "featuresDict = constructFeatDict();\n",
    "concatAB, ygold = loaddata(featuresDict);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BATCHSIZE = 64;\n",
    "#dtrn, ddev, dtst = dividedataset(concatAB, ygold, trnper, devper, tstper; batchsize= BATCHSIZE);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
